## Tasks
#### we train three models:`LSTM/ CNN/ BERT` for the `Text Entailment Task` and the
`Semantic Relatedness Task` on the `SICK data`

## model
#### 3-layer-Bi-LSTM
![](https://imgur.com/Bq3wE91.jpg)

#### CNN
![](https://imgur.com/MRsIZRg.jpg)

#### BERT
![](https://imgur.com/FijgdaM.jpg)


## Result
#### task 1
![](https://imgur.com/twVjQ25.jpg)

#### task 2
![](https://imgur.com/NUQ3fMr.jpg)

